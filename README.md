# 操作系统

教材：汤小丹  计算机操作系统（第四版）

## 第一章 操作系统引论

#### 操作系统作用

1.OS作为用户和计算机硬件之间的接口

2.OS作为计算机系统资源的管理者

3.OS实现了对计算机资源的抽象

#### 操作系统的演进

由单道批处理系统演进为多道批处理系统：

前者是一个一个连续处理任务，内存中只保持一道作业，系统的资源得不到充分的利用，在系统进行I/O请求的时候CPU处于等待状态，由于I/O系统的低速性更使得CPU的利用率显著降低；

后者将提交的作业存放在外存中，组成一个“后备队列”，由作业调度程序按照一定的算法从中选择若干个作业调入内存，使它们共享CPU和系统资源，多道程序交替运行使得CPU处于忙碌状态。在A程序I/O的CPU空挡时间，可以调度B运行。

####  操作系统的基本特性

1.并发：正是由于程序可以并发执行，才使得OS能有效增加系统吞吐量

​	区别两个概念，**并发和并行**：并发是说在一段时间内宏观上有多个程序在同时运行，而微观下程序只能分时交替运行；并行是说多个事件在同一时刻发生。

2.共享：在OS环境下的资源共享成为资源复用，是指系统中的资源可供内存中多个并发执行的进程共同使用。资源共享分为互斥共享方式和同时访问方式。

3.虚拟：在OS中 通过某种技术将一个物理实体变为若干个逻辑上的对应物的功能成为“虚拟”。这种技术有时分复用和空分复用，时分复用的例子是多道程序并发执行，瓜分时间片；空分复用的例子有信道的频段划分。

## 第二章 进程的描述和控制

**进程的定义**：进程控制块（Process Control Block, PCB)是为进程设计的一个数据结构，用来描述进程的基本情况和活动过程。由程序段，相关的数据段和PCB三部分就构成进程的实体，简称进程。

#### 进程的基本状态和转换

1.就绪状态：指进程已经处于准备好运行的状态，已分配到除CPU以外的必要资源。只需要获得CPU即可运行。

2.执行状态：正在执行

3.阻塞状态：正在执行的进程由于发生了诸如I/O请求，申请缓冲区失败等事件，暂时无法继续执行时的状态。

4.创建状态：创建一个进程有若干步骤，（1）申请一个空白的PCB并填入控制信息（2）分配运行时的资源（3）将该进程转入就绪状态并插入就绪队列中。完成创建的过程就是创建状态。

5.终止状态：将PCB清零归还系统。

6.**挂起操作**和进程状态的转换：如果进程正在执行，挂起之后将暂停执行；若原本处于就绪状态则该进程此时暂不接受调度。与挂起操作相对应的操作时激活（Suspend/Active）。活动就绪-->静止就绪  活动阻塞-->静止阻塞  静止就绪是不会被调度执行的。



#### 进程控制块PCB的作用

1.是进程存在于系统的**唯一标识**。

2.保护进程的CPU现场信息：当进程因阻塞而停止运行时，必须<u>保留自己的现场信息</u>，以供再度调用时恢复。

3.提供进程管理所需要的信息：记录了程序和数据的内外存地址，维护了进程所需**资源**的清单。

4.PCB还维护了进程处于何种**状态**，即就绪，运行，阻塞这些进程状态；还保存有进程优先级，等待时间，已执行时间等调度算法需要用到的数据。

5.实现与其他进程的同步与通信，PCB具有用于实现**进程通信**的区域。

**PCB记录的信息**：进程标识符；处理机状态；进程调度信息；进程控制信息

1.唯一地标识一个进程

2.处理机的上下文，主要是寄存器状态：通用寄存器；指令计数器；程序状态字PSW；用户栈指针

3.进程状态；进程优先级；进程调度所需信息

4.程序和数据的地址；进程同步和通信机制；资源清单；链接下一个PCB的指针

#### 进程控制

操作系统内核：与硬件紧密相关的模块，常用的驱动程序以及运行频率较高的模块，它们被安排在紧靠硬件的软件层次中，常驻内存，通常被称为OS内核。

##### <u>内核态和用户态</u>：

内核态具有较高的权限，能执行一切指令，访问所有的寄存器和存储区；用户态仅能执行规定的指令，访问指定的寄存器和存储区。

##### <u>系统调用</u>：

[ JavaGuide]: https://github.com/Snailclimb/JavaGuide	"操作系统面试题·"

用户态(user mode) : 用户态运行的进程或可以直接读取用户程序的数据。

系统态(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！也就是说在我们运行的用户程序中，凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

#### 进程同步

##### 信号量机制

这是一种卓有成效的进程同步工具。

1. **整型信号量**：定义为一个用于表示资源数目的整型量S，仅能通过<u>两个标准的原子操作</u>来访问，wait(S)/signal(S)

这两个操作被称为**P，V操作**。原子操作不可中断。

```
wait(S){
	while(S<=0);//忙等
	S--;
}
signal(S){
	S++;
}
```

wait操作中，只要S<=0，就会不断测试，不遵循“让权等待”，忙等。

2. **记录型信号量**

   区别于上面的忙等，采取了让权等待的策略。记录现有能支配的资源数目，当资源数目为0时，此时信号量转化为互斥信号量。其中的list进程链表指针，是用于连接上述的所有等待的进程。

```C
typedef struct{
    int value;//临界资源的数目
    struct process_control_block *list;
}semaphore;

wait(semaphore *S){
    S->value--;//可分配的该类资源减少1个
    if(S->value<0) block(S->list);//该进程自我阻塞
}

signal(semaphore *S){
    S->value++;//资源数目加1
    if(S->value<=0){
        wakeup(S->list);//仍有等待该资源的进程被阻塞，唤醒阻塞队列的第一个等待的进程
    }
}
```

3. **AND型信号量**

   一个进程需要获得两个或者多个共享资源后方能执行任务，容易形成进程死锁。AND同步机制的基本思想是要么资源全部分配给进程，要么一个都不分配，这样可以避免死锁。

   **哲学家进餐问题**的解决就可以用AND信号量：仅当哲学家的左右两只筷子都可用时，才允许他拿起筷子进餐。

   ```C
   Semaphore chopstick[]={1,1,1,1,1};
   do{
   	Swait(chopstick[(i+1)%5], chopstick[i]);
   	Ssignal(chopstick[(i+1)%5],chopstick[i]);
   }while(true)
   ```

   

4. **信号量集**

   可以一次申请/释放多个信号量。

##### **信号量的应用**

###### 利用信号量实现进程互斥。

​		将某临界资源设置一互斥信号量mutex，**各进程访问该资源的临界区CS置于wait(mutex)和signal(mutex)操作中间即可**。这一对互斥信号量就相当于锁。

联想到了<u>JVM中synchronized的实现</u>：jvm用monitorenter和monitorexit指令对同步提供显式支持。

> *https://www.cnblogs.com/huangyin/p/6586469.html*

###### 利用信号量实现前驱关系。

​		P1-->P2  希望P1中的S1语句结束之后再执行P2中的S2语句。

​		使两个进程共享一个公用的信号量S，在P1中 signal(S) ; 在P2中 wait(S)

##### 管程

​		可以利用共享数据结构抽象地表示系统中的共享资源，并且将对该共享资源的操作定义为一种过程。代表共享资源的数据结构和上述过程组成的资源管理程序共同构成了一个操作系统的资源管理模块，我们称之为管程。

​		管程由四部分组成 : 管程的**名称**；局部于管程的**共享数据结构**说明；对该数据结构进行**操作**的一组过程；对局部于管程的共享数据设置**初始值**的语句。

​		进程要访问临界资源时，都只能通过管程间接访问，而**管程每次只准许一个进程进入管程**，从而实现进程互斥。

​		管程的同步工具：如同步操作原语wait和signal

```C
//管程封装生产者消费者活动
//每次只允许一个进程进入管程
Monitor Producer_Consumer{
    item[] buffer;
    int in, out;
    condition notFull, notEmpty;
    //定义函数
    void put(Item it){
        
    }
    void get(Item it){
        
    }
}
//生产者消费者问题
void Producer{
    new Item it;
    PC.put(it);
}
void Consumer{
    Item it = PC.get();
}
```

#### <u>进程通信</u>

进程之间要传递大量数据时，可以利用OS提供的高级通信工具。高级通信机制分为四大类：共享存储器系统， 管道通信系统，消息传递系统，客户端-服务器系统。

1.共享存储器：在内存中划出一块共享存储区域，进程之间可以通过该区域交换信息。

2.管道通信：连接一个读进程和写进程，又称pipe文件。写进程以字符流形式将数据送入管道，接受方拿数据。

3.消息传递：将通信数据封装成消息，利用操作系统提供的通信命令在进程间完成消息传递。计算机网络就是这么干的，将消息称为报文。

4.客户机-服务器：（1）套接字：基于网络型的不说了，还有基于文件型的，套接字关联一个文件，通过读写文件实现通信（2）远程调用：远程过程调用RPC：这个有点像计网的web服务器中的应用调用。

[进程间通信IPC]: https://www.jianshu.com/p/c1015f5ffa74

1. **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
2. **有名管道(Names Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循**先进先出(first in first out)**。有名管道的名字存在于文件系统中，内容存放在内存中。
3. **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
4. **消息队列(Message Queuing)** ：管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。**
5. **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间**同步**。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
6. **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要**依靠某种同步操作**，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
7. **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

## 第三章 处理机调度与死锁

#### 处理机作业调度

<u>调度目标</u>：CPU利用率；对诸进程的公平性；I/O，计算任务的平衡性；作业的平均周转时间；

系统吞吐量高（吞吐量指在单位时间内系统所完成的作业数）；响应时间快；截止时间的保证…

##### 调度层次

**1.高级调度**：调度对象是作业

**2.中级调度**：内存调度，为了提高内存利用率和系统吞吐量，把暂时不能运行的进程调至外存或挂起，换成能跑的进程

**3.低级调度：**调度对象是进程



**作业控制块**（Job Control Block **JCB**）：为了管理和调度作业，给每个作业设置了一个标志，有作业类型，作业状态，调度信息，资源需求，资源使用状态等信息。

**作业调度**：根据JCB的信息，设计一定的算法，选取哪些作业调入内存，并为它们创建进程，分配必要的资源。然后将新创建的进程-排在就绪队列上等待调度，因此也把作业调度成为接纳调度。每次执行作业调度时，都需要做出两个决定：接纳多少作业？接纳哪些作业？

##### 先来先服务（FCFS）和短作业优先（SJF）

1.每次从就绪队列中选择一个最先进队列的进程，为之分配处理机。该进程一直运行到完成或发生某事件而阻塞之后，进程调度程序才将处理机分配给其他进程。可按进程优先级设置多个队列，每个队列用FCFS算法。

2.在实际情况中，短作业进程占有很大的比例。SFJ以作业的长短计算优先级，作业越短，优先级越高。从外存的作业后备队列中选择若干个估计运行时间最短的作业，优先调度。

##### 优先级调度算法（PSA）和高响应比优先调度算法（HRRN）

1.基于作业的紧迫程度，赋予作业相应的优先级。

2.考虑作业的等待时间以及作业运行时间的调度算法。根据**等待时间**和**作业运行时间**设置动态优先级，令其随着等待时间延长而增加，等到足够的时间必然有机会获得处理机。

##### 进程调度机制

进程调度的任务有三：1.保存处理机现场信息 2.按某种算法选取进程 3.把处理器分配给线程

进程调度机制：维护一个队列-->将进程从队列中取出 即分派进程-->上下文切换

进程调度方式：**抢占还是非抢占**

1.非抢占式：如果某进程分配到了cpu,则进程一直进行下去直至完成 ，或者阻塞中断才考虑切换；

2.抢占方式： 根据若干原则抢占处理机， 如某个进程执行期间来了一个优先级更高的进程，则会立刻被抢占cpu进行进程的切换。

#####  轮转调度算法

让就绪队列的每个进程每次只运行一个时间片。轮转法（**RR**）中，系统根据FCFS策略，将所有的就绪进程排成一个就绪队列，设置一个时间间隔产生一次中断，完成一次调度，将CPU分配给队首进程，若上一个进程没结束将之放在队尾。

比较关键的是**时间片大小的确定**：应略大于一次典型交互所需要的时间，使得交互式进程能在一个时间片内完成，从而获得很小的响应时间。

##### 多级反馈队列调度算法

1.设置多个就绪队列，第一个优先级最高，第二个次之，其余递减。

2.每个队列采取FCFS算法，若在该时间片内完成则撤离系统，若没有完成则放在下一个队列的队尾等候。

3.按照队列优先级调度。首先调度优先级高的队列中的进程。若高优先级中队列中已没有调度的进程，则调度次优先级队列中的进程。例如：Q1,Q2,Q3三个队列，当且仅当在Q1中没有进程等待时才去调度Q2，同理，只有Q1,Q2都为空时才会去调度Q3。

#### 死锁

##### 产生死锁的必要条件 

四个条件都必须满足：1.互斥；2.请求和保持条件，就是抓住自己获得的资源保持不放 3.不可抢占原则，资源只有在进程使用完之后自己释放 4.循环等待条件，必然存在一个进程-资源的循环链。

**处理死锁**的方法：预防 避免 检测 解除

##### 预防死锁

破坏产生死锁的四个条件中的一个或者几个。由于互斥是必然发生的，因此只能从后面的三个下手。

###### 破坏“请求和保持”条件

第一种协议：是之前说过的，要么全给要么不给的思路。这种协议的有点简单，易行且安全。但是会出现资源被严重浪费，使得进程经常会发生饥饿现象。

第二种协议：是对第一种协议的改进，它允许一个线程只获得运行初期的资源后就开始运行，运行的过程中再**逐渐释放**已经分配给自己的，且已经用完的资源，然后请求新的资源。

###### 破坏“不可抢占”条件

该协议规定，当一个进程取得了某些资源，又提出新的资源请求而又不能得到满足时，它必须释放已经保持的所有资源，在以后需要的时候重新申请。

实现起来比较复杂，且需要比较高的代价。会使得前一阶段的工作的失效，延长了进程的周转时间，增加了系统开销，降低了系统吞吐量。

###### 破环“循环等待”条件

对系统内的所有资源进行线性排序，并赋予不同的序号。然后采用这样的预防协议：规定每个进程必须<u>按照序号递增的顺序请求资源</u>。再采用这样的策略形成的资源分配图中，不可能出现环路，因而破坏了”循环等待“的条件。

缺点是需要保证系统的各类资源线性排序相对稳定，这就限制了新类型设备的增加；编号时需要考虑作业实际使用这些资源的顺序，否则会造成资源的浪费。

##### 避免死锁

把系统的状态分为安全状态和不安全状态，处于不安全状态时有可能进入死锁。

**银行家算法避免死锁**  四个数据结构分别描述系统可用资源，所有进程对A资源的最大需求，系统的资源分配，进程还需要多少资源。

算法思想：经过初步检查现有资源可以分配给某个线程，然后试探者将资源分配给该线程，修改上述的四个结构，然后执行**安全性算法**。安全性算法实质也是尝试，试着把Available资源分配给线程，若能够满足该线程所需，则该线程可以顺利完成，标记线程为true，回收所有资源，然后尝试下一个，若所有的线程最后都被标记为true则系统安全。可参考博文如下：

> https://www.cnblogs.com/chuxiuhong/p/6103928.html

##### 死锁的检测与解除

###### 死锁状态检测

操作系统不断监视系统进展情况，判断死锁是否发生。一旦死锁发生则采取专门的措施，解除死锁并以最小代价恢复系统运行。其中检测死锁用到了资源分配图：

![img](D:\ProgramData\MyNotes\操作系统\image\资源分配图.jpg)

​	用圆圈代表一个进程，用框代表一类资源。由于一种类型的资源可能有多个，用框中的一个点代表一类资源中的一个资源。从进程到资源的有向边叫请求边，表示该进程申请一个单位的该类资源；从资源到进程的边叫分配边，表示该类资源已经有一个资源被分配给了该进程。

![img](D:\ProgramData\MyNotes\操作系统\image\资源分配图的化简.jpg)

让某个进程先获得所需的所有资源，同时意味着其他线程让出资源，直至该线程完成之后释放资源，成为一个孤立节点，消去所有的边，以此反复，若能消去所有的边，使所有的进程节点都成为孤立节点，则称该图是可完全简化的，否则是不可完全简化的，且判断为死锁状态。

###### 死锁的解除

一旦检测出死锁，就应立即釆取相应的措施，以解除死锁。死锁解除的主要方法有：

1) 资源剥夺法。挂起某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但应防止被挂起的进程长时间得不到资源，而处于资源匮乏的状态。

2) 撤销进程法。强制撤销部分、甚至全部死锁进程并剥夺这些进程的资源。撤销的原则可以按进程优先级和撤销进程代价的高低进行。

3) 进程回退法。让一（多）个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而不是被剥夺。要求系统保持进程的历史信息，设置还原点。

> https://blog.csdn.net/jgm20475/article/details/81297819

### 第四章  存储器管理

#### 存储器的层次结构

##### 多层结构的存储器系统

###### 存储器的多层结构

存储层次至少应该有三级：最高层是CPU寄存器，中间为主存，最底层为辅存。还可以根据具体的功能分为寄存器，高速缓存，主存储器，磁盘缓存，固定磁盘，可移动磁盘。越靠近CPU，存储介质访问速度越快，价格越高。

###### 可执行存储器

寄存器和主存储器又被称为可执行存储器，进程可以再很短的时钟周期内使用一条load/store语句对可执行存储器进行访问，而辅存是要通过I/O操作访问。

###### 主存储器和寄存器

主存储器又被称为内存或者主存，通常处理机都是从主存中取得指令和数据的，并将其所获得的指令/数据放在指令/数据寄存器中，或者反之。

寄存器的访问速度最快，完全能与CPU协调工作。

###### 高速缓存和磁盘缓存

高速缓存是介于寄存器和存储器之间的存储器，主要用于备份主存中较为常用的数据，以减少处理机对主存的访问次数，这里也引入了数据的有效性问题。

为了缓和主存和磁盘的访问速度的不一致，设置了磁盘缓存，再主存中暂时存放的一部分磁盘数据和信息，减少访问磁盘的次数。磁盘缓存与高速缓存不同，不是一种实际存在的存储器，而是利用了主存中部分存储空间。

<u>以上的寄存器，高速缓存，主存，磁盘缓存都是操作系统直接管辖，掉电之后存储的信息将不再存在。</u>



#### 操作系统的内存管理

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

（下面内容的一个概览）

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

1. **块式管理** ： 远古时代的计算机操系统的内存管理方式。将内存分为几个固定大小的块，每个块中只包含一个进程。如果程序运行需要内存的话，操作系统就分配给它一块，如果程序运行只需要很小的空间的话，分配的这块内存很大一部分几乎被浪费了。这些在每个块中未被利用的空间，我们称之为碎片。
2. **页式管理** ：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。
3. **段式管理** ： 页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，每一段的空间又要比一页的空间小很多 。但是，最重要的是段是有实际意义的，每个段定义了一组逻辑信息，例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。
4. **段页式管理**：段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

#### 程序的链接和装入

用户程序要在系统中运行，必须先将它装入内存，然后将其转变为一个可执行程序，通常有以下几个步骤：

1.编译， 由编译程序对用户源程序进行编译，形成若干个目标**模块**（Object Module），每个模块在这个阶段都使用相对地址，起始地址都为0。

2.链接，由链接程序将编译之后形成的目标模块与它们所需要的库函数链接再一起，形成一个完整的装入模块（Load Module）

3.装入，由装入程序将模块装入内存。

##### 程序的链接

1.静态链接：编译之后的模块之间有相互调用，把这些模块都拼接起来。<u>修改相对地址 （原来的模块的起始地址都为0，改为拼接之后的地址）</u>，变换调用的符号（引用地址跟着变化）。

2.动态链接：第一种方法是，若实现不知道调用情况，只能将所有可能运行到的模块全部装入内存。第二种方法类似延迟加载，将链接推迟到运行时进行，临时取装入内存。在执行中未被用到的目标模块，都不会被调入内存和被链接装入。

##### 程序的装入（内存）

**有绝对装入方式，可重定位装入方式 ，以及动态运行时的装入方式。**

###### 绝对装入方式

适用于小型计算机系统，单道程序。用户程序经过编译后，将产生绝对地址（物理地址）的目标代码，这个可以由程序员直接给定。绝对装入程序中的相对地址与实际内存地址完全相同。

###### 可**重定位**装入方式（静态重定位）

在多道程序环境下，编译程序不能预知经过编译后得到的目标模块应放在内存的何处。因此，用户程序编译所得的目标模块的起始地址都是从0开始，程序的其他地址都是相对于起始地址计算的。这种装入可以根据内存具体情况将装入模块装入内存的适当区域。

<img src="D:\ProgramData\MyNotes\操作系统\image\可重定位.jpg" style="zoom: 67%;" />

在装入时需要对目标程序的指定和数据地址的修改过程称为重定位。又因为地址变换通常是在装入时一次完成 ，不再改变，故称之为静态重定位。

###### 动态运行时的装入方式

可重定位方式不能允许在程序运行的时候在内存中移动位置，而程序在运行的时候在内存中的位置可能经常要改变，例如有对换功能的系统中，进程可能被多次换出换入，换入的地址通常不一样，在这种情况下应采用动态运行方式。

装入内存时并不直接把逻辑地址转换为物理地址，而是把地址转换推迟到程序真正要执行的时候才进行。为了地址转换不影响指令的执行操作，需要一个重定位寄存器的支持。





#### 连续分配存储管理方式

将用户程序装入内存，怎么分配内存空间成了问题。

单一连续分区略过

##### 固定分区分配

为了能在内存中放多道程序，且不会相互干扰。固定分区是将用户空间分为若干个大小固定的区域，在每个分区中装一道作业，每个分区内的程序**可以并发执行**。这是最早的可以运行多道作业的分区式存储管理方式。分区的方式有分区大小相等和不等两种。这种方式一定会造成存储空间的浪费。

##### 动态分区分配

动态分区又被称为可变分区分配，是根据进程需要，动态地为之分配内存空间。需要设计分区分配所用的数据结构，分区分配算法和回收操作。

为了实现动态分区分配，设计了描述空闲分区和已分配分区的情况，为分配提供依据。有两种常见的数据结构形式：**空闲分区表**和**空闲分区链**。前者记录每个空闲分区的情况，包括分区号，大小，分区始址等数据项，后者则是用了双向链表的形式将空闲分区连在一起，为了检索方便，在分区尾部设置状态位（如1标志为已经分配出去了）和分区大小表目。

##### 动态分区分配算法

###### 基于顺序搜索的动态分区分配算法

适用于不太大的系统，链长较短。

1.**首次适应算法** 遍历空闲分区链表找到一个能满足大小需求的空闲分区，优先利用内存中的低址部分，会保留高址部分的大空闲区，好处是可以为大作业分大的空间，坏处是容易留下很多难以利用的小分区（碎片）。

2.**循环首次适应算法**  从上一次找的的空闲分区的下一个空闲分区开始查找，需要维护一个起始查询指针。这种方式会使得内存中的空闲分区更加均匀。

3.**最佳适应算法**  每次去找能满足要求，又是最小的空闲分区分配给作业，避免”大材小用“。但是也会留下碎片，而且需要对空闲分区进行排序。

4.**最坏适应算法**  与上面的相反，总是去找一个最大的空闲区，这样可以使得剩下的空闲区不至于太小，同时，最坏适应碎发的查找效率很高，只要把空闲分区按照容量从大到小的顺序形成一空闲分区链，只要看第一个分区能否满足要求即可。

###### 基于索引搜索的动态分区分配算法

在大中型系统往往用索引搜索

1.**快速适应算法**

将空闲分区根据容量大小进行分类，相同大小的连成链表，然后维护一个**管理索引表**记录各个链表头和对应的大小。快速分配，查找效率高，能保留大分区，不产生碎片。缺点是归还分区比较复杂，系统开销较大。

2.**伙伴系统**

伙伴系统规定：无论已分配分区或空闲分区，其大小均为2的k次幂，k为整数，1<=k<=m,k大于等于1，小于等于m。当需要为进程分配一个长度为n的存储空间时，首先计算一个i值，使n大于2^(i-1)次方,小于等于2^i次方，然后在空闲分区大小为2^i的空闲分区链表中查找，若找到，即把该空闲分区分配给进程，否则把大的分割成小的，再分配给进程。

3.**哈希**

将快速适应算法中的管理索引表换成哈希表，查找速度快一些。

##### 动态可重定位分配算法

**紧凑** 把分散的多个小分区，拼接成一个大分区

<img src="D:\ProgramData\MyNotes\操作系统\image\紧凑.jpg" style="zoom: 50%;" />

**重定位寄存器**  适应于【 动态运行装入】，用它来存放程序在内存中的起始地址，程序在执行时，真正访问的内存地址是装入模块的逻辑地址与重定位寄存器中的地址相加后的地址。

与动态分区分配算法基本上相同，加上了紧凑的功能。这种分配把小的分区都整理连续排放，合并不连续的碎片以适应大分区的需要。





#### 对换（Swapping）

有一种场景：内存中的进程都被阻塞不干活，而外存又有许多作业因内存空间不足不能运行，这是一种严重的浪费，使得系统的吞吐量下降。所谓”对换“， 是指把内存中暂时无法运行的进程搬到外存中去，腾出空间给已具备运行条件的进程。

对换分为**整体对换**和**页面（分段）对换**，前者是以进程为单位的，故称之为”进程对换“；后者是以一个进程的”页面“或者”分段“为单位进行的，故称”页面/分段对换“。

##### 对换空间管理

###### 对换空间的管理目标

对换空间的管理，在具有对换功能的OS中，通常把磁盘空间分为**文件区**和**对换区**两部分。文件区主要就是存储文件，访问不是很频繁；对换空间存放的是从内存换出的进程，对换操作的频率较高。对于文件区管理主要目标是提高文件存储**空间的利用率**，对对换空间管理的主要目标是提高**进程换入和换出的速度**。

###### 对换空间的分配与回收

由于对换空间的分配方式采用的也是连续分配方式，因此回收和分配算法和内存的分配回收的方法一致，也是首次适应算法，循环首次适应算法和最佳适应算法。

##### 进程的换入和换出

进程的换入换出需要花费很多时间，如果发现有许多进程运行时经常发生缺页且已经出现内存紧张的情况，才启用对换程序。

###### 进程的换出

1.选择被换出的进程。选择处于阻塞状态或者睡眠状态的进程，如果有多个这样的进程时，应当选择优先级最低的进程作业换出进程。

2.换出的过程。首先申请对换空间，如果申请成功，则启动磁盘，将该进程的程序和数据传送到 磁盘的对换区上。传输没有出现错误则可回收该进程所占用的内存空间。

###### 进程的换入

查看PCB集合中的所有进程的状态，从中找到“就绪”状态但已经换出的进程，申请内存，然后将进程从外存调入内存。





#### 分页存储管理方式

连续分配方式会产生很多“碎片”，为了更充分地利用内存空间，引入离散分配，有分页式，分段式，段页式三种管理方式。

##### 分页存储管理的基本方法

**地址结构** 分页地址中的地址结构包含两部分--页号和位移量。

**页面和物理块** 将进程的逻辑地址分成若干个页，页号。相应地把内存的物理地址页分成若干的块，块号。在为进程分配内存时，以块为单位，将进程中的若干个页装入不连续的物理块中。进程的最后一页经常装不满一个块就变成了不可利用的碎片。

**页表**

实现页号到物理块号的映射关系的存储数据结构。

![img](D:\ProgramData\MyNotes\操作系统\image\页表)

#### 地址变换机构

利用页面映射表来实现页号到物理块号的变换，借助于上面的页表。

###### 基本的地址变换机构

页表大多驻留在**内存**中，在系统中设置一个页表寄存器PTR，存放着页表在内存中的始址和页表的长度。当进程要访问某个逻辑地址的数据时，需要将有效地址分为页号和页内地址两部分，计算得出在页表中的位置，将之装入物理地址寄存器中。

###### 具有快表的地址变换机构

上面的访问方式需要两次访问内存，第一次访问页表形成物理地址，第二次直接寻址获得数据。这使得计算机的处理速度降低一半，只换来空间利用率的提高，不合算。为了提高地址变换速度，增设了具有并行查询能力的特殊高速**缓存**寄存器，又称为“联想寄存器”，也称为快表。就是缓存物理块号，省去从内存中的页表查找。

![img](D:\ProgramData\MyNotes\操作系统\image\分页系统的地址变换机构)

###### 多级页表

为了提高内存的空间性能，提出了多级页表的概念；但是提到空间性能是以浪费时间性能为基础的，因此为了补充损失的时间性能，提出了快表（即 TLB）的概念。 不论是快表还是多级页表实际上都利用到了程序的局部性原理，局部性原理在后面的虚拟内存这部分会介绍到。引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。多级页表属于时间换空间的典型场景



#### 分段存储管理方式

为了满足用户在编程和使用上多方面的要求，引入分段存储。将程序分成若干个段，每一个段相对独立。以段作为基本单位，实现和满足信息共享，信息保护，动态链接，以及信息的动态增长。段的划分是有意义的，根据程序的结构进行划分，如分成主程序段，子程序段，数据段和栈段等等。每一个段是一个相对独立的逻辑单位。

###### 分段系统的基本原理

1.**分段** 按照程序的逻辑结构分成若干个段，给每个段进行编号，每一个段都从0开始编址，并采用一段连续的地址空间，段的长度由相应的逻辑信息组的长度决定，因此各段长度不相等。分段后的逻辑地址结构：段号+段内地址

2.**段表**  物理地址和逻辑地址的映射表，结构是段号+段长+基址

3.**地址变换机构**  段表寄存器，用于存放段表始址和段表长度

动态链接：不是将所有的目标程序段都链接起来，而是当程序要运行时，将主程序和它立即需要用到的目标程序装入内存，需要调用某个目标段才调入内存进行链接。类似的有段号和段表，这里就不多说了。

###### 对比分页存储管理方式

分页管理中的页只是存放信息的物理块，并无完整的逻辑意义，这样一个可被共享的过程往往会占用数十个页面，这就为共享增加了困难。段是信息的逻辑单位，因此可以为共享过程建立一个独立的段，简化了共享的实现。

分页系统以页面作为内存分配的基本单位，能够有效地提高内存利用率，而分段系统以段作为内存分配的基本单位，能够更好的满足用户多方面的需要。

#### 段页式存储方式

“各取所长”  这种新系统的优势在于便于分享，分段可共享，易于保护，可动态链接等一系列有点，又能像分页系统那样，很好地解决内存的外部碎片问题。将用户程序分成若干个段，然后把每个段分成若干个页。需要同时配置段表和页表。

[简书]: https://www.jianshu.com/p/4261380861d0	"段页式管理"



### 第五章  虚拟存储器

#### 局部性原理

要想更好地理解虚拟内存技术，必须要知道计算机中著名的**局部性原理**。另外，局部性原理既适用于程序结构，也适用于数据结构，是非常重要的一个概念。

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

局部性原理表现在以下两个方面：

1. **时间局部性** ：如果程序中的某条指令一旦执行，不久以后该指令可能再次执行；如果某数据被访问过，不久以后该数据可能再次被访问。产生时间局部性的典型原因，是由于在程序中存在着大量的循环操作。
2. **空间局部性** ：一旦程序访问了某个存储单元，在不久之后，其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内，这是因为指令通常是顺序存放、顺序执行的，数据也一般是以向量、数组、表等形式簇聚存储的。

时间局部性是通过将近来使用的指令和数据保存到**高速缓存存储器**中，并使用高速缓存的层次结构实现。空间局部性通常是使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现。虚拟内存技术实际上就是**建立了 “内存一外存”的两级存储器**的结构，利用局部性原理实现髙速缓存。



#### 为什么要虚拟存储

之前说过的存储器都要求将一个作业全部放入内存才能够运行，于是会出现作业很大无法装入内存的问题。虚拟存储是通过逻辑上扩充内存容量来解决问题的。

<u>应用程序在运行之前没有必要全部装入内存</u>，<u>需要用到时发出缺页/段请求，调入内存继续执行</u>，若内存已满，则可以利用<u>页/段的置换功能</u>腾出空间。这样可以再小内存中运行大程序，或者装入更多的程序提高并发度。

###### 虚拟存储器

基于局部性原理，在程序装入时，可以将程序的一部分装入内存，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**。

**虚拟存储器的定义** 具有**请求调入和置换**功能，能从逻辑上对内存容量加以扩充的一种存储器系统。

**虚拟存储器的实现方法** 建立再离散分配存储管理方式的基础上。

<u>分页请求系统</u> 再分页系统的基础上加入了请求调页功能和页面置换功能所形成的页式虚拟存储，允许用户程序只装入少量页面程序即可启动运行。

<u>分段请求系统</u> 在分段系统的基础上增加请求调段功能和分段置换功能形成的..

硬件支持：请求**分段/页的段/表机制**； **缺页/段的中断机构**； **地址变换机构**

软件支持：实现请求调页的软件和实现页面置换的软件。





#### 请求分页存储管理方式

##### 请求分页中的硬件支持

###### 请求页表机制

在请求分页系统中最主要的数据结构就是**请求页表**，基本作用仍然是将用户地址空间中的逻辑地址映射为内存空间中的物理地址。

(1) 状态位P：用于指示该页是否已调入内存，供程序訪问时參考。 

(2) 訪问字段A：用于记录本页在一段时间内**被访问的次数**，或记录本页近期已有多长时间未被訪问，供选择换出页面时參考。

(3) 改动位M：表示该页在调入内存后**是否被改动过**。因为内存中的每一页都在外存上保留一份副本，因此，若未被改动，在置换该页时就不需再将该页写回到外存上，以降低系统的开销和启动磁盘的次数；若已被改动，则必须将该页重写到外存上，以保证外存中所保留的始终是最新副本 。简言之，M位供置换页面时參考。 

(4) 外存地址：用于指出该页在外存上的地址，一般是物理块号，供调入该页时參考。 

###### 缺页中断机构

没啥好说的

###### 地址变换机构

![img](D:\ProgramData\MyNotes\操作系统\image\1-140F102004L08.jpg)

##### 请求分页中的内存分配

就是如何分配物理块：最小物理块的确定；分配策略。

###### 最小物理块

取决于指令的格式，功能和寻址方式。

###### 内存分配策略

1）固定分配局部置换。进程分配到一组固定物理块，运行期间内存空间不变，如发生缺页则从分配到的n个页面中置换。

2）可变分配全局置换。进程首先分到一些物理块，缺页之后会从系统中选择任意一个进程中的页进行调换，这会使得被选中的进程缺页率增加。

3）可变分配局部置换。只会在自己的进程页面置换，不会影响到其他进程。

###### 物理块的分配策略

1）平均

2）根据进程大小按照比例划分

3）考虑优先级的划分

#### 页面置换算法

在进程运行过程中，若其所要访问的页面不在内存，而需要把它们调入内存，但内存已无空闲空间时，就需要从内存中调出一页程序或者数据到磁盘的对换区。好的页面置换算法应该具有较低的页面更换频率，应该将哪些不会访问或者一段时间不会用到的页面换出。

1.最佳置换算法：”先知“，知道了所有页面的使用顺序，是一种绝对理想化的算法。

2.先进先出页面置换算法：选择最早进入进程物理块的进行置换。

##### 最近最久未使用和最少使用置换算法

###### LRU最久未使用置换算法

选择最近最久未使用的页面予以淘汰，该算法赋予每个页面一个**访问字段**，用来记录一个页面自上次被访问以来所经历的时间。当需要淘汰一个页面的时候，就选择现有页面中其时间最长的一个。LRU算法是一种比较好的算法，但硬件要求比较多，可由移位寄存器或者是栈结构来实现。

1）移位寄存器  保存进程的页面使用情况。

2）栈 栈顶到栈底是访问新到旧的情况。

###### LFU最少使用算法

选择在最近时期使用最少的页面作为淘汰页。跟LRU类似，也是用移位寄存器实现的。每次访问就将移位寄存器的最高位置1，然后一定时间右移一位。

###### Clock置换算法

是一种LRU的近似算法，改善LRU需要的硬件支持依赖程度。

###### 简单的Clock置换算法

相比于LRU每个页面需要多位的寄存器，Clock的简单置换算法只为每页置1位访问位。页面组成循环队列，页面被访问就置1。在选择淘汰页面时，如果访问位为0，则换出，若为1，则0，然后检查下一个页面。

###### 改进型的Clock置换算法

除了页面的使用情况，还增加置换代价的考量。在将一个页面换出时，如果该页被修改过，则必须将该页写回磁盘，即修改过的页面在换出时所付出的代价比未修改过的页面大。

有四类页面：访问位A和修改位M的亮亮组合。第一类A=0 M=0是最佳淘汰页。

这种改进的好处是减少磁盘的I/O,但是会增加扫描次数。

##### 页面缓冲算法

页面换进换出的开销对系统性能的影响很大。主要的影响因素有：页面置换算法，将已经修改的页面写回磁盘的频率，以及将磁盘内容读入内存的频率。

好的页面置换算法的影响最大。对于第二点，可以在系统中建立一个修改页面的链表，记录修改过的页面，当被换出页面数目达到一定值时，再将它们写回磁盘，可以显著减少I/O的次数。对于第三点，由于链表上已经有了缓存，因此可以首先从链表中获取页面，这样可以减少换入页面的开销。

###### 页面缓冲算法PBA

特点是显著降低页面换进、换出的频率，是的磁盘I/O的频率降低；由于换入换出的开销大幅减少，因此可以采用较为简单的页面置换策略，如FIFO。需要的数据结构1）空闲页面链表





### 第六章 输入输出系统



